{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1e33d2",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2019/10/how-to-build-knowledge-graph-text-using-spacy/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad9c7f5",
   "metadata": {},
   "source": [
    "#### Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2026ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'KEATING REVISES DOWN AUSTRALIAN GROWTH FORECAST Treasurer Paul Keating forecast economic growth at slightly under two % in the financial year ending June this year,down from the 2.25 % forecast contained in the 1986 / 87 budget delivered last August.Australia \\' s terms of trade also fell,by 18 %,over the past two years,Paul Keating told Parliament.Terms of trade are the difference between import and export price indexes.Despite the figures,the budget forecast of about 1.75 % annual growth in employment would be met,Keating said.Unemployment is currently at 8.2 % of the workforce.\" This government is dragging Australia through a trading holocaust the kind of which we have not seen since the Second World War ,\" Keating said.\" we are not pushing this place into a recession.we are not only holding we gains on unemployment,we are bringing unemployment down ,\" Paul Keating said,adding that the government had help Australia avoid recession .'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb0628d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KEATING REVISES DOWN AUSTRALIAN GROWTH FORECAST Treasurer Paul Keating forecast economic growth at slightly under two % in the financial year ending June this year,down from the 2.25 % forecast contained in the 1986 / 87 budget delivered last August.Australia \\' s terms of trade also fell,by 18 %,over the past two years,Paul Keating told Parliament.Terms of trade are the difference between import and export price indexes.Despite the figures,the budget forecast of about 1.75 % annual growth in employment would be met,Keating said.Unemployment is currently at 8.2 % of the workforce.\" This government is dragging Australia through a trading holocaust the kind of which we have not seen since the Second World War ,\" Keating said.\" we are not pushing this place into a recession.we are not only holding we gains on unemployment,we are bringing unemployment down ,\" Paul Keating said,adding that the government had help Australia avoid recession .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c65ea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEATING ... compound\n",
      "REVISES ... ROOT\n",
      "DOWN ... ROOT\n",
      "AUSTRALIAN ... compound\n",
      "GROWTH ... compound\n",
      "FORECAST ... compound\n",
      "Treasurer ... dobj\n",
      "Paul ... compound\n",
      "Keating ... nsubj\n",
      "forecast ... ROOT\n",
      "economic ... amod\n",
      "growth ... dobj\n",
      "at ... advmod\n",
      "slightly ... advmod\n",
      "under ... quantmod\n",
      "two ... nummod\n",
      "% ... npadvmod\n",
      "in ... prep\n",
      "the ... det\n",
      "financial ... amod\n",
      "year ... pobj\n",
      "ending ... acl\n",
      "June ... npadvmod\n",
      "this ... det\n",
      "year ... npadvmod\n",
      ", ... punct\n",
      "down ... advmod\n",
      "from ... prep\n",
      "the ... det\n",
      "2.25 ... nummod\n",
      "% ... compound\n",
      "forecast ... pobj\n",
      "contained ... acl\n",
      "in ... prep\n",
      "the ... det\n",
      "1986 ... nummod\n",
      "/ ... punct\n",
      "87 ... prep\n",
      "budget ... pobj\n",
      "delivered ... acl\n",
      "last ... amod\n",
      "August ... npadvmod\n",
      ". ... punct\n",
      "Australia ... nsubj\n",
      "' ... punct\n",
      "s ... ROOT\n",
      "terms ... nsubj\n",
      "of ... prep\n",
      "trade ... pobj\n",
      "also ... advmod\n",
      "fell ... ccomp\n",
      ", ... punct\n",
      "by ... prep\n",
      "18 ... nummod\n",
      "% ... pobj\n",
      ", ... punct\n",
      "over ... prep\n",
      "the ... det\n",
      "past ... amod\n",
      "two ... nummod\n",
      "years ... pobj\n",
      ", ... punct\n",
      "Paul ... compound\n",
      "Keating ... nsubj\n",
      "told ... ROOT\n",
      "Parliament ... dobj\n",
      ". ... punct\n",
      "Terms ... nsubj\n",
      "of ... prep\n",
      "trade ... pobj\n",
      "are ... ROOT\n",
      "the ... det\n",
      "difference ... attr\n",
      "between ... prep\n",
      "import ... nmod\n",
      "and ... cc\n",
      "export ... conj\n",
      "price ... compound\n",
      "indexes ... pobj\n",
      ". ... punct\n",
      "Despite ... prep\n",
      "the ... det\n",
      "figures ... pobj\n",
      ", ... punct\n",
      "the ... det\n",
      "budget ... compound\n",
      "forecast ... nsubjpass\n",
      "of ... prep\n",
      "about ... advmod\n",
      "1.75 ... nummod\n",
      "% ... nmod\n",
      "annual ... amod\n",
      "growth ... pobj\n",
      "in ... prep\n",
      "employment ... pobj\n",
      "would ... aux\n",
      "be ... auxpass\n",
      "met ... ccomp\n",
      ", ... punct\n",
      "Keating ... nsubj\n",
      "said ... ROOT\n",
      ". ... punct\n",
      "Unemployment ... nsubj\n",
      "is ... ROOT\n",
      "currently ... advmod\n",
      "at ... prep\n",
      "8.2 ... nummod\n",
      "% ... pobj\n",
      "of ... prep\n",
      "the ... det\n",
      "workforce ... pobj\n",
      ". ... punct\n",
      "\" ... ROOT\n",
      "This ... det\n",
      "government ... nsubj\n",
      "is ... aux\n",
      "dragging ... ccomp\n",
      "Australia ... dobj\n",
      "through ... prep\n",
      "a ... det\n",
      "trading ... compound\n",
      "holocaust ... pobj\n",
      "the ... det\n",
      "kind ... appos\n",
      "of ... prep\n",
      "which ... pobj\n",
      "we ... nsubj\n",
      "have ... aux\n",
      "not ... neg\n",
      "seen ... relcl\n",
      "since ... prep\n",
      "the ... det\n",
      "Second ... compound\n",
      "World ... compound\n",
      "War ... pobj\n",
      ", ... punct\n",
      "\" ... punct\n",
      "Keating ... nsubj\n",
      "said ... ROOT\n",
      ". ... punct\n",
      "\" ... ROOT\n",
      "we ... nsubj\n",
      "are ... aux\n",
      "not ... neg\n",
      "pushing ... ccomp\n",
      "this ... det\n",
      "place ... dobj\n",
      "into ... prep\n",
      "a ... det\n",
      "recession.we ... pobj\n",
      "are ... aux\n",
      "not ... preconj\n",
      "only ... advmod\n",
      "holding ... advcl\n",
      "we ... nsubj\n",
      "gains ... ccomp\n",
      "on ... prep\n",
      "unemployment ... pobj\n",
      ", ... punct\n",
      "we ... nsubj\n",
      "are ... aux\n",
      "bringing ... ccomp\n",
      "unemployment ... dobj\n",
      "down ... prt\n",
      ", ... punct\n",
      "\" ... punct\n",
      "Paul ... compound\n",
      "Keating ... nsubj\n",
      "said ... ROOT\n",
      ", ... punct\n",
      "adding ... advcl\n",
      "that ... mark\n",
      "the ... det\n",
      "government ... nsubj\n",
      "had ... aux\n",
      "help ... ccomp\n",
      "Australia ... nsubj\n",
      "avoid ... ccomp\n",
      "recession ... dobj\n",
      ". ... punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for tok in doc:\n",
    "    print(tok.text, \"...\", tok.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74a74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3acc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "  ## chunk 1\n",
    "    ent1 = \"\"\n",
    "    ent2 = \"\"\n",
    "\n",
    "    prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
    "    prv_tok_text = \"\"   # previous token in the sentence\n",
    "\n",
    "    prefix = \"\"\n",
    "    modifier = \"\"\n",
    "  \n",
    "    for tok in nlp(sent):\n",
    "    ## chunk 2\n",
    "    # if token is a punctuation mark then move on to the next token\n",
    "        if tok.dep_ != \"punct\":\n",
    "        # check: token is a compound word or not\n",
    "            if tok.dep_ == \"compound\":\n",
    "                prefix = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "                if prv_tok_dep == \"compound\":\n",
    "                    prefix = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      # check: token is a modifier or not\n",
    "        if tok.dep_.endswith(\"mod\") == True:\n",
    "            modifier = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "            if prv_tok_dep == \"compound\":\n",
    "                modifier = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      ## chunk 3\n",
    "        if tok.dep_.find(\"subj\") == True:\n",
    "            ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
    "            prefix = \"\"\n",
    "            modifier = \"\"\n",
    "            prv_tok_dep = \"\"\n",
    "            prv_tok_text = \"\"      \n",
    "\n",
    "      ## chunk 4\n",
    "        if tok.dep_.find(\"obj\") == True:\n",
    "            ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
    "        \n",
    "      ## chunk 5  \n",
    "      # update variables\n",
    "        prv_tok_dep = tok.dep_\n",
    "        prv_tok_text = tok.text\n",
    "  #############################################################\n",
    "\n",
    "    return [ent1.strip(), ent2.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d750c630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia', 'recession']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(\"Paul Keating said,adding that the government had help Australia avoid recession .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86406e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ... det\n",
      "22-year ... nummod\n",
      "- ... punct\n",
      "old ... nsubj\n",
      "recently ... advmod\n",
      "won ... ROOT\n",
      "ATP ... compound\n",
      "Challenger ... compound\n",
      "tournament ... dobj\n",
      ". ... punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(\"The 22-year-old recently won ATP Challenger tournament.\")\n",
    "\n",
    "for tok in doc:\n",
    "    print(tok.text, \"...\", tok.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6694eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nagal ... nsubj\n",
      "won ... ROOT\n",
      "the ... det\n",
      "first ... amod\n",
      "set ... dobj\n",
      ". ... punct\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Nagal won the first set.\")\n",
    "\n",
    "for tok in doc:\n",
    "    print(tok.text, \"...\", tok.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c76cd69",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9622/3480883181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import wikipedia sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcandidate_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcandidate_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# import wikipedia sentences\n",
    "candidate_sentences = text\n",
    "candidate_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92e370fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "x = tokenize.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfccb2ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9622/3677200973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mentity_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mentity_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import tqdm as tqdm\n",
    "entity_pairs = []\n",
    "\n",
    "for i in tqdm(x):\n",
    "    entity_pairs.append(get_entities(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9f1fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(sent):\n",
    "\n",
    "    doc = nlp(sent)\n",
    "\n",
    "      # Matcher class object \n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "      #define the pattern \n",
    "    pattern = [{'DEP':'ROOT'}, \n",
    "                {'DEP':'prep','OP':\"?\"},\n",
    "                {'DEP':'agent','OP':\"?\"},  \n",
    "                {'POS':'ADJ','OP':\"?\"}] \n",
    "\n",
    "    matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "    matches = matcher(doc)\n",
    "    k = len(matches) - 1\n",
    "\n",
    "    span = doc[matches[k][1]:matches[k][2]] \n",
    "\n",
    "    return(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e443fccb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Matcher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9622/3636512866.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_relation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"John completed the task\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_9622/1762333177.py\u001b[0m in \u001b[0;36mget_relation\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m# Matcher class object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;31m#define the pattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Matcher' is not defined"
     ]
    }
   ],
   "source": [
    "get_relation(\"John completed the task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17105e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
