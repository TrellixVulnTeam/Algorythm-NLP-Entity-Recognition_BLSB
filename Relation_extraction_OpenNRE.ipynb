{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Relation_extraction_OpenNRE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMySyPIKo43zRkfSpad9EF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yusufakcakaya/Algorythm-NLP-Entity-Recognition/blob/Nichelle/Relation_extraction_OpenNRE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: 1. https://analyticsindiamag.com/beginners-guide-to-opennre-toolkit/ \n",
        "        2. https://towardsdatascience.com/from-text-to-knowledge-the-information-extraction-pipeline-b65e7e30273e\n"
      ],
      "metadata": {
        "id": "wLTLXHq1oZB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting to google drive"
      ],
      "metadata": {
        "id": "RJlUPFAx7103"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Connecting google drive"
      ],
      "metadata": {
        "id": "RADe-Rnb7cKH"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpcHOzHqmET2",
        "outputId": "459f3114-8c20-4126-d8a0-32f1c3626444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloning OpenNRE "
      ],
      "metadata": {
        "id": "u-mIa4gN767L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thunlp/OpenNRE.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0b0bckQn98V",
        "outputId": "0308184f-ffde-470e-ab8f-10163bb56509"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OpenNRE'...\n",
            "remote: Enumerating objects: 1514, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 1514 (delta 81), reused 82 (delta 42), pack-reused 1377\u001b[K\n",
            "Receiving objects: 100% (1514/1514), 266.83 MiB | 26.54 MiB/s, done.\n",
            "Resolving deltas: 100% (901/901), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd OpenNRE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGzTtxign_e6",
        "outputId": "069d3e87-b20c-4dac-f76e-dee2e85f2e85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OpenNRE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TwtIPvQn_o2",
        "outputId": "cf6f9393-89a6-4573-fec9-58e2766a063d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 17 kB/s \n",
            "\u001b[?25hCollecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 42.9 MB/s \n",
            "\u001b[?25hCollecting pytest==5.3.2\n",
            "  Downloading pytest-5.3.2-py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 42.4 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.1\n",
            "  Downloading scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.4.1)\n",
            "Collecting nltk>=3.6.4\n",
            "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.8 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (4.62.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Collecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 26.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (3.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (3.4.2)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (8.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (21.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (0.2.5)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (1.11.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (4.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 4)) (1.1.0)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2022.1.18-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
            "\u001b[K     |████████████████████████████████| 748 kB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.4->-r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.3.2->-r requirements.txt (line 3)) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.3.2->-r requirements.txt (line 3)) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 2)) (3.0.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.4.0->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (2.10)\n",
            "Installing collected packages: regex, tokenizers, sentencepiece, sacremoses, pluggy, transformers, torch, scikit-learn, pytest, nltk\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed nltk-3.6.7 pluggy-0.13.1 pytest-5.3.2 regex-2022.1.18 sacremoses-0.0.47 scikit-learn-0.22.1 sentencepiece-0.1.96 tokenizers-0.9.2 torch-1.6.0 transformers-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading pretrained model from opennre"
      ],
      "metadata": {
        "id": "rAIZpjBz8O_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opennre"
      ],
      "metadata": {
        "id": "qhIwpUk1n_vd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = opennre.get_model('wiki80_cnn_softmax')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB_7RVRRn_1v",
        "outputId": "00484c54-a5a3-44fb-a24d-b864f7832af2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-20 13:30:32,023 - root - INFO - Initializing word embedding with word2vec.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.infer({'text': 'He was the son of ashok, and grandson of rahul.', 'h': {'pos': (18, 46)}, 't': {'pos': (78, 91)}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P97Ogj5dn_7x",
        "outputId": "f5706360-1873-4917-e301-dda422036e70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('child', 0.3211628794670105)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9MOrkNWp84bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entity linking"
      ],
      "metadata": {
        "id": "XZZxeh668aQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = \"Elon Musk is a business magnate, industrial designer, and engineer. Elon Musk is the founder, CEO, CTO, and chief designer of SpaceX. Elon Musk is also early investor, CEO, and product architect of Tesla, Inc. Elon Musk is also the founder of The Boring Company and the co-founder of Neuralink. A centibillionaire, Musk became the richest person in the world in January 2021, with an estimated net worth of $185 billion at the time, surpassing Jeff Bezos. Musk was born to a Canadian mother and South African father and raised in Pretoria, South Africa. Elon Musk briefly attended the University of Pretoria before moving to Canada aged 17 to attend Queen's University. Elon Musk transferred to the University of Pennsylvania two years later, where Elon Musk received dual bachelor's degrees in economics and physics. Elon Musk moved to California in 1995 to attend Stanford University, but decided instead to pursue a business career. Elon Musk went on co-founding a web software company Zip2 with Elon Musk brother Kimbal Musk.\""
      ],
      "metadata": {
        "id": "j4ZKnADFoAB2"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article1 = \"Residents of Brussels with solar panels installed can expect to receive around 10% more green certificates for the electricity generated in 2022 than they did last year. The Region wants to continue to guarantee the repayment of investments in solar over seven years, Bruzz reports, following advice to this effect from energy regulator Brugel. In 2021, the number of green certificates (GSCs) for new solar panels in Brussels decreased by 20 to 46%, depending on the power category of the installation, to mirror the falling cost of installations over the last several years (in Flanders and Wallonia, green certificates were abolished back in 2014). But now the subsidy will rise by around 10% for each category, as the cost of installing solar panels begins to climb again. “Energy regulator Brugel noticed that the cost price of the installations has increased due to the rising price of raw materials,” said Raphaël Boucquey, legal advisor for renewable energy at Brussels Environment. “The aim is to be able to continue to guarantee a return on investment in solar panels within seven years thanks to the 10% increase in green certificates.” The increase in the number of green certificates only applies to new installations from 1 January 2022, and is not retroactive.\""
      ],
      "metadata": {
        "id": "gtrjYBsm8zUw"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "from string import punctuation\n",
        "import nltk\n",
        "\n",
        "ENTITY_TYPES = [\"human\", \"person\", \"company\", \"enterprise\", \"business\", \"geographic region\",\n",
        "                \"country\", \"human settlement\", \"geographic entity\", \"territorial entity type\", \"organization\"]\n",
        "\n",
        "def wikifier(text, lang=\"en\", threshold=0.8):\n",
        "    \"\"\"Function that fetches entity linking results from wikifier.com API\"\"\"\n",
        "    # Prepare the URL.\n",
        "    data = urllib.parse.urlencode([\n",
        "        (\"text\", text), (\"lang\", lang),\n",
        "        (\"userKey\", \"tgbdmkpmkluegqfbawcwjywieevmza\"),\n",
        "        (\"pageRankSqThreshold\", \"%g\" %\n",
        "         threshold), (\"applyPageRankSqThreshold\", \"true\"),\n",
        "        (\"nTopDfValuesToIgnore\", \"100\"), (\"nWordsToIgnoreFromList\", \"100\"),\n",
        "        (\"wikiDataClasses\", \"true\"), (\"wikiDataClassIds\", \"false\"),\n",
        "        (\"support\", \"true\"), (\"ranges\", \"false\"), (\"minLinkFrequency\", \"2\"),\n",
        "        (\"includeCosines\", \"false\"), (\"maxMentionEntropy\", \"3\")\n",
        "    ])\n",
        "    url = \"http://www.wikifier.org/annotate-article\"\n",
        "    # Call the Wikifier and read the response.\n",
        "    req = urllib.request.Request(url, data=data.encode(\"utf8\"), method=\"POST\")\n",
        "    with urllib.request.urlopen(req, timeout=60) as f:\n",
        "        response = f.read()\n",
        "        response = json.loads(response.decode(\"utf8\"))\n",
        "    # Output the annotations.\n",
        "    results = list()\n",
        "    for annotation in response[\"annotations\"]:\n",
        "        # Filter out desired entity classes\n",
        "        if ('wikiDataClasses' in annotation) and (any([el['enLabel'] in ENTITY_TYPES for el in annotation['wikiDataClasses']])):\n",
        "\n",
        "            # Specify entity label\n",
        "            if any([el['enLabel'] in [\"human\", \"person\"] for el in annotation['wikiDataClasses']]):\n",
        "                label = 'Person'\n",
        "            elif any([el['enLabel'] in [\"country\", \"geographic region\", \"human settlement\", \"geographic entity\", \"territorial entity type\"] for el in annotation['wikiDataClasses']]):\n",
        "                label = 'Location'\n",
        "            elif any([el['enLabel'] in [\"company\", \"enterprise\", \"business\", \"organization\"] for el in annotation['wikiDataClasses']]):\n",
        "                label = 'Organization'\n",
        "    \n",
        "            else:\n",
        "                label = None\n",
        "\n",
        "            results.append({'title': annotation['title'], 'wikiId': annotation['wikiDataItemId'], 'label': label,\n",
        "                            'characters': [(el['chFrom'], el['chTo']) for el in annotation['support']]})\n",
        "    return results"
      ],
      "metadata": {
        "id": "M4z3sq1YqDGY"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "dAaW7a8KqDZU"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linking = wikifier(article1)"
      ],
      "metadata": {
        "id": "qR0KpK8iqDru"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linking"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OixUCOQvqD6u",
        "outputId": "1f4e01de-43d1-40d1-fa02-860a5f748c37"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'characters': [(13, 20), (418, 425), (969, 976)],\n",
              "  'label': 'Location',\n",
              "  'title': 'Brussels',\n",
              "  'wikiId': 'Q240'},\n",
              " {'characters': [(580, 587)],\n",
              "  'label': 'Location',\n",
              "  'title': 'Flanders',\n",
              "  'wikiId': 'Q234'},\n",
              " {'characters': [(593, 600)],\n",
              "  'label': 'Location',\n",
              "  'title': 'Wallonia',\n",
              "  'wikiId': 'Q231'}]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entity relation extraction"
      ],
      "metadata": {
        "id": "va-56-2E8gkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools "
      ],
      "metadata": {
        "id": "2StW1KMiqmXq"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opennre"
      ],
      "metadata": {
        "id": "s4n-apA4qzmd"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeSYqrCVyQRX",
        "outputId": "41fa7e89-b616-489e-9bdb-226415c831d3"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ie_pipeline(text, relation_threshold=0.9, entities_threshold=0.8):\n",
        "    # Prepare the URL.\n",
        "    data = urllib.parse.urlencode([\n",
        "        (\"text\", text), (\"relation_threshold\", relation_threshold),\n",
        "        (\"entities_threshold\", entities_threshold)])\n",
        "    \n",
        "    url = \"http://localhost:5000?\" + data\n",
        "    req = urllib.request.Request(url, data=data.encode(\"utf8\"), method=\"GET\")\n",
        "    with urllib.request.urlopen(req, timeout=150) as f:\n",
        "        response = f.read()\n",
        "        response = json.loads(response.decode(\"utf8\"))\n",
        "    # Output the annotations.\n",
        "    return response"
      ],
      "metadata": {
        "id": "7gyr5WJayP7e"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_punctuation(s):\n",
        "    \"\"\"Removes all punctuation from a string\"\"\"\n",
        "    return ''.join(c for c in s if c not in punctuation)"
      ],
      "metadata": {
        "id": "_hrJywc12gHa"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deduplicate_dict(d):\n",
        "    return [dict(y) for y in set(tuple(x.items()) for x in d)]"
      ],
      "metadata": {
        "id": "cv6BhGnL2Ghp"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hello_ie():\n",
        "\n",
        "  relations_list = list()\n",
        "  entities_list = list()\n",
        "  text = article\n",
        "  for sentence in nltk.sent_tokenize(text):\n",
        "      sentence = strip_punctuation(sentence)\n",
        "      entities = wikifier(sentence, threshold=0.8)\n",
        "      entities_list.extend(\n",
        "          [{'title': el['title'], 'wikiId': el['wikiId'], 'label': el['label']} for el in entities])\n",
        "      # Iterate over every permutation pair of entities\n",
        "      for permutation in itertools.permutations(entities, 2):\n",
        "          for source in permutation[0]['characters']:\n",
        "              for target in permutation[1]['characters']:\n",
        "                  # Relationship extraction with OpenNRE\n",
        "                  data = model.infer(\n",
        "                      {'text': sentence, 'h': {'pos': [source[0], source[1] + 1]}, 't': {'pos': [target[0], target[1] + 1]}})\n",
        "                  if data[1] > 0.9:\n",
        "                      relations_list.append(\n",
        "                          {'source': permutation[0]['title'], 'target': permutation[1]['title'], 'type': data[0]})\n",
        "\n",
        "  return {'entities': deduplicate_dict(entities_list), 'relations': deduplicate_dict(relations_list)}\n",
        "\n"
      ],
      "metadata": {
        "id": "kNGUyj4gqbRq"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = hello_ie()\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvuRYvoqqbfQ",
        "outputId": "d1eebf08-d107-404e-8c9d-43dd4b3d227a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'entities': [{'label': 'Location',\n",
              "   'title': 'University of Pretoria',\n",
              "   'wikiId': 'Q604444'},\n",
              "  {'label': 'Organization', 'title': 'SpaceX', 'wikiId': 'Q193701'},\n",
              "  {'label': 'Organization', 'title': 'Neuralink', 'wikiId': 'Q29043471'},\n",
              "  {'label': 'Organization',\n",
              "   'title': 'The Boring Company',\n",
              "   'wikiId': 'Q28874479'},\n",
              "  {'label': 'Location', 'title': 'Pretoria', 'wikiId': 'Q3926'},\n",
              "  {'label': 'Location',\n",
              "   'title': 'University of Pennsylvania',\n",
              "   'wikiId': 'Q49117'},\n",
              "  {'label': 'Person', 'title': 'Jeff Bezos', 'wikiId': 'Q312556'},\n",
              "  {'label': 'Organization', 'title': 'Tesla, Inc.', 'wikiId': 'Q478214'},\n",
              "  {'label': 'Person', 'title': 'Elon Musk', 'wikiId': 'Q317521'},\n",
              "  {'label': 'Person', 'title': 'Kimbal Musk', 'wikiId': 'Q6409751'},\n",
              "  {'label': 'Location', 'title': 'Stanford University', 'wikiId': 'Q41506'}],\n",
              " 'relations': [{'source': 'University of Pennsylvania',\n",
              "   'target': 'Elon Musk',\n",
              "   'type': 'subsidiary'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "l_c0HbgF4rRJ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(w.items()), columns=['column1','column2']).T"
      ],
      "metadata": {
        "id": "L6pmoNCIqbtd"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "g6G7UauPqb3i",
        "outputId": "dfbda977-17da-4473-fee2-a353c768885f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8e107c71-3d37-43f2-bc91-204ffad18fbc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>entities</td>\n",
              "      <td>relations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'title': 'University of Pretoria', 'wikiId':...</td>\n",
              "      <td>[{'source': 'University of Pennsylvania', 'tar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e107c71-3d37-43f2-bc91-204ffad18fbc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e107c71-3d37-43f2-bc91-204ffad18fbc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e107c71-3d37-43f2-bc91-204ffad18fbc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   0                                                  1\n",
              "0                                           entities                                          relations\n",
              "1  [{'title': 'University of Pretoria', 'wikiId':...  [{'source': 'University of Pennsylvania', 'tar..."
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    }
  ]
}